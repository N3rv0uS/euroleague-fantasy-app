\
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ÎšÎ±Ï„ÎµÎ²Î¬Î¶ÎµÎ¹ EuroLeague player stats Î±Î½Î¬ ÏƒÎµÎ¶ÏŒÎ½ ÎºÎ±Î¹ Ï„Î± ÏƒÏÎ¶ÎµÎ¹ ÏƒÎµ CSV/Excel/SQLite.
Î ÏÎ¿Ï„Î¹Î¼Î¬ Ï„Î¿ Ï€Î±ÎºÎ­Ï„Î¿ "euroleague-api". Î‘Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹/Î±Ï€Î¿Ï„ÏÏ‡ÎµÎ¹, ÎºÎ¬Î½ÎµÎ¹ fallback ÏƒÎµ raw HTTP ÏƒÏ„Î¿ public swagger (Î±Î½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿).
"""

import argparse
import json
import os
import sys
from typing import List, Dict
import pandas as pd

# ---------------- Advanced Metrics ----------------
def _get_col(df, *candidates, default=0):
    for c in candidates:
        if c in df.columns:
            return df[c]
    return pd.Series(default, index=df.index, dtype="float64")

def add_advanced_metrics(df: pd.DataFrame) -> pd.DataFrame:
    """
    Î ÏÎ¿ÏƒÎ¸Î­Ï„ÎµÎ¹ derived / advanced metrics Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Î¾Î±Î½Î±Ï…Ï€Î¿Î»Î¿Î³Î¯Î¶ÎµÎ¹ PIR.
    Î‘Ï€Î±Î¹Ï„ÎµÎ¯ ÏŒÏƒÎ¿ Î³Î¯Î½ÎµÏ„Î±Î¹ Ï„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ (Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚ Ï€Î±Î¯Î¶Î¿Ï…Î½ Î±Î½Î¬ endpoint):
    - 2PM/2PA, 3PM/3PA Î® FGM/FGA
    - FTM/FTA
    - PTS, AST, TOV, MIN, GP
    - team_name (Î® Team)
    """

    out = df.copy()

    # Column aliases
    team = _get_col(out, "Team", "team_name")
    gp   = _get_col(out, "GP", "gp")
    min_ = _get_col(out, "MIN", "min")
    pts  = _get_col(out, "PTS", "pts")
    ast  = _get_col(out, "AST", "ast")
    tov  = _get_col(out, "TOV", "tov")
    oreb = _get_col(out, "OREB", "oreb")
    dreb = _get_col(out, "DREB", "dreb")
    treb = _get_col(out, "REB", "reb", default=oreb.add(dreb, fill_value=0))

    p2m  = _get_col(out, "2PM", "fg2m", "twoptm")
    p2a  = _get_col(out, "2PA", "fg2a", "twopta")
    p3m  = _get_col(out, "3PM", "fg3m", "threeptm")
    p3a  = _get_col(out, "3PA", "fg3a", "threepta")
    ftm  = _get_col(out, "FTM", "ftm")
    fta  = _get_col(out, "FTA", "fta")

    fgm  = _get_col(out, "FGM", "fgm", default=p2m + p3m)
    fga  = _get_col(out, "FGA", "fga", default=p2a + p3a)

    # ----- Shooting profiles -----
    # eFG% = (FGM + 0.5*3PM) / FGA
    out["eFG%"] = ((fgm + 0.5 * p3m) / fga).replace([pd.NA, pd.NaT], 0).fillna(0)

    # TS% = PTS / (2*(FGA + 0.44*FTA))
    denom_ts = (2 * (fga + 0.44 * fta))
    out["TS%"] = (pts / denom_ts).replace([pd.NA, pd.NaT], 0).fillna(0)

    # 3PAr = 3PA / FGA
    out["3PAr"] = (p3a / fga).replace([pd.NA, pd.NaT], 0).fillna(0)

    # FTr = FTA / FGA
    out["FTr"] = (fta / fga).replace([pd.NA, pd.NaT], 0).fillna(0)

    # AST/TOV
    out["AST/TOV"] = (ast / tov.replace(0, pd.NA)).fillna(pd.NA).replace([pd.NaT], pd.NA)
    out["AST/TOV"] = out["AST/TOV"].fillna(0)

    # TOV% â‰ˆ TOV / (FGA + 0.44*FTA + TOV)
    denom_tov = (fga + 0.44*fta + tov)
    out["TOV%"] = (tov / denom_tov).replace([pd.NA, pd.NaT], 0).fillna(0)

    # ----- Per-36 pace-neutral rates -----
    # Î ÏÎ¿Ï„Î¹Î¼Î¿ÏÎ¼Îµ per-36 Î³Î¹Î± ÏƒÏ…Î³ÎºÏÎ¹ÏƒÎ¹Î¼ÏŒÏ„Î·Ï„Î±.
    min_safe = min_.replace(0, pd.NA)
    for col, label in [(pts, "PTS/36"), (treb, "REB/36"), (ast, "AST/36"),
                       (tov, "TOV/36"), (p3m, "3PM/36"), (oreb, "OREB/36"),
                       (dreb, "DREB/36")]:
        out[label] = (col / min_safe * 36).fillna(0)

    # ----- Usage% (Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¹ÏƒÏ„Î¹ÎºÏŒ, Î±Ï€ÏŒ player+team totals) -----
    # USG% = 100 * ((FGA + 0.44*FTA + TOV) * (TeamMinutes/5)) / (MIN * (TeamFGA + 0.44*TeamFTA + TeamTOV))
    # Î˜Î± Ï€ÏÎ¿ÏƒÎµÎ³Î³Î¯ÏƒÎ¿Ï…Î¼Îµ TeamMinutes/Ï€Î±Î¹Ï‡Î½Î¯Î´Î¹ Î±Ï€ÏŒ Ï„Î± Î±Î¸ÏÎ¿Î¯ÏƒÎ¼Î±Ï„Î± Ï„Ï‰Î½ Ï€Î±Î¹ÎºÏ„ÏÎ½. Î‘Î½ Î»ÎµÎ¯Ï€ÎµÎ¹ -> 200.
    # Î“Î¹Î± TeamFGA/FTA/TOV Î±Î½Î¬ Ï€Î±Î¹Ï‡Î½Î¯Î´Î¹: Î¬Î¸ÏÎ¿Î¹ÏƒÎ¼Î± per-game Ï€Î±Î¹ÎºÏ„ÏÎ½ Ï„Î·Ï‚ Î¯Î´Î¹Î±Ï‚ Î¿Î¼Î¬Î´Î±Ï‚.
    # Group by team:
    out["_player_poss_comp"] = (fga + 0.44*fta + tov)
    # Î§ÏÎµÎ¹Î±Î¶ÏŒÎ¼Î±ÏƒÏ„Îµ Î­Î½Î± ÎºÎ±Î¸Î±ÏÏŒ string Î¼Îµ team id Î³Î¹Î± groupby
    team_key = team.astype(str).fillna("Unknown")
    agg = out.groupby(team_key).agg(
        Team_MIN_pg = ("MIN", "sum") if "MIN" in out.columns else ("min", "sum"),
        Team_FGA_pg = (lambda x: fga.groupby(team_key).sum()[x.name]) if False else ("_player_poss_comp", "sum"), # placeholder
    )

    # Î•Ï€ÎµÎ¹Î´Î® Î´ÎµÎ½ Î¼Ï€Î¿ÏÎ¿ÏÎ¼Îµ Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎ¿Ï…Î¼Îµ custom ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ .agg Î³Î¹Î± Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ­Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ ÎµÏÎºÎ¿Î»Î±, Î¾Î±Î½Î±Ï†Ï„Î¹Î¬Ï‡Î½Î¿Ï…Î¼Îµ:
    team_df = pd.DataFrame({
        "Team": team_key,
        "MIN": min_,
        "FGA": fga,
        "FTA": fta,
        "TOV": tov,
    })
    team_totals = team_df.groupby("Team").sum(numeric_only=True)
    team_totals["TeamMinutes_pg"] = team_totals["MIN"].where(team_totals["MIN"] > 0, 200)
    team_totals["TeamPossComp_pg"] = team_totals["FGA"] + 0.44*team_totals["FTA"] + team_totals["TOV"]
    team_totals = team_totals[["TeamMinutes_pg", "TeamPossComp_pg", "FGA", "FTA", "TOV"]]

    out = out.join(team_totals, on=team_key, how="left")

    denom_usg = (min_safe * out["TeamPossComp_pg"])
    numer_usg = (out["_player_poss_comp"] * (out["TeamMinutes_pg"] / 5.0))
    out["USG%"] = (100 * numer_usg / denom_usg).replace([pd.NA, pd.NaT], 0).fillna(0)

    # ----- AST% (playmaking share, simplified) -----
    # AST% â‰ˆ 100 * AST / ( (MIN/TeamMinutes)*TeamFGM - FGM )
    team_fgm = team_df.groupby("Team")["FGA"].sum() * 0  # placeholder to keep index
    # Î‘Î½ Î­Ï‡Î¿Ï…Î¼Îµ FGM ÏƒÏ„Î®Î»Î·, Ï€Î¬ÏÏ„Î·Î½ Î±Ï€ÏŒ team_df (Î´ÎµÎ½ Ï„Î·Î½ Î­Ï‡Î¿Ï…Î¼Îµ ÎµÎ´Ï). Î˜Î± Ï…Ï€Î¿Î»Î¿Î³Î¯ÏƒÎ¿Ï…Î¼Îµ Ï‰Ï‚ 2PM+3PM Î±Î½ Î»ÎµÎ¯Ï€ÎµÎ¹.
    team_fgm_df = pd.DataFrame({
        "Team": team_key,
        "FGM": fgm
    }).groupby("Team").sum(numeric_only=True)
    out = out.join(team_fgm_df.rename(columns={"FGM":"TeamFGM_pg"}), on=team_key, how="left")

    denom_astp = ((min_safe / out["TeamMinutes_pg"]) * out["TeamFGM_pg"] - fgm)
    out["AST%"] = (100 * ast / denom_astp.replace(0, pd.NA)).fillna(0)

    # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î¿Î¯ Î²Î¿Î·Î¸Î·Ï„Î¹ÎºÏÎ½
    out.drop(columns=[c for c in ["_player_poss_comp"] if c in out.columns], inplace=True)

    # Clip ÏƒÎµ Î»Î¿Î³Î¹ÎºÎ¬ ÏŒÏÎ¹Î±
    for c in ["eFG%", "TS%", "3PAr", "FTr", "TOV%"]:
        out[c] = out[c].clip(lower=0, upper=1)
    for c in ["USG%", "AST%"]:
        out[c] = out[c].clip(lower=0, upper=100)

    return out

# Î ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬: Ï‡ÏÎ®ÏƒÎ· Ï„Î¿Ï… community package
def try_import_euroleague_api():
    try:
        from euroleague_api.player_stats import PlayerStats  # type: ignore
        from euroleague_api.euroleague_data import EuroleagueData  # type: ignore
        return PlayerStats, EuroleagueData
    except Exception:
        return None, None

def fetch_with_package(season: int, competition_code: str, mode: str) -> pd.DataFrame:
    PlayerStats, EuroleagueData = try_import_euroleague_api()
    if PlayerStats is None:
        raise RuntimeError("Î¤Î¿ package 'euroleague-api' Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î¿.")
    # Î¤Î± Î¿Î½ÏŒÎ¼Î±Ï„Î±/Î¼Î­Î¸Î¿Î´Î¿Î¹ Î²Î±ÏƒÎ¯Î¶Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· (Î²Î». README Ï„Î¿Ï… project).
    ps = PlayerStats(competition_code=competition_code)
    # Î£Ï…Î½Î®Î¸Î· modes: perGame | perMinute | accumulated
    df = ps.get_season_player_stats(season=season, statistic_mode=mode)
    # Î•Î¼Ï€Î»Î¿Ï…Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Î¼Îµ metadata Î¿Î¼Î¬Î´Ï‰Î½/Ï€Î±Î¹ÎºÏ„ÏÎ½ Î±Î½ Î´Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î±
    return df

def fetch_with_raw_requests(season: int, competition_code: str, mode: str) -> pd.DataFrame:
    """
    1) Î ÏÎ¿ÏƒÏ€Î±Î¸ÎµÎ¯ ÏƒÏÎ³Ï‡ÏÎ¿Î½Î± API endpoints Ï„Î¿Ï… api-live.euroleague.net
    2) Fallback: ÎºÎ¬Î½ÎµÎ¹ scraping Ï„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ± Î±Ï€ÏŒ Ï„Î¿ /stats/expanded/ (ÏŒÏ€Ï‰Ï‚ ÏƒÏ„Î¿ site)
    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ DataFrame Î¼Îµ Ï„Î± rowsÂ· Î±Î½ Î´ÎµÎ½ Î²ÏÎµÎ¸Î¿ÏÎ½, ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ ÎºÎµÎ½ÏŒ DF.
    """
    import re
    import requests
    import pandas as pd

    base_api = "https://api-live.euroleague.net"
    base_web = "https://www.euroleaguebasketball.net/el/euroleague/stats/expanded/"
    season_code = f"{competition_code}{season}"  # Ï€.Ï‡. E2025

    # ---------- (A) API candidates ----------
    api_candidates = [
        # Î ÏÎ¿Ï„Î¹Î¼Î¿ÏÎ¼Îµ Ï„Î¿ Range (ÏŒÏ€Ï‰Ï‚ ÏƒÏ„Î¿ site)
        f"{base_api}/v1/players/stats?seasonMode=Range&fromSeasonCode={season_code}"
        f"&toSeasonCode={season_code}&competitionCode={competition_code}&statisticMode={mode}&size=10000",
        # Î•Î½Î±Î»Î»Î±ÎºÏ„Î¹ÎºÎ¬ Ï„Î¿ seasonCode
        f"{base_api}/v1/players/stats?seasonCode={season_code}&competitionCode={competition_code}"
        f"&statisticMode={mode}&size=10000",
        # Î Î±Î»Î¹ÏŒ pattern
        f"{base_api}/v1/players/stats?season={season}&competitionCode={competition_code}&statisticMode={mode}"
    ]

    last_err = None
    for url in api_candidates:
        try:
            print(f"ğŸ” Trying API URL: {url}")
            r = requests.get(url, timeout=60)
            print("   â†’ status:", r.status_code)
            r.raise_for_status()
            data = r.json()
            rows = data.get("data", data)
            df = pd.json_normalize(rows)
            if len(df) > 0:
                print(f"âœ… API returned {len(df)} rows")
                return df
        except Exception as e:
            last_err = e
            print(f"âš ï¸ API attempt failed: {e}")

    # ---------- (B) Fallback: scrape Î±Ï€ÏŒ expanded page ----------
    web_url = (
        f"{base_web}?size=1000&viewType=traditional"
        f"&seasonMode=Range&statisticMode={mode}"
        f"&fromSeasonCode={season_code}&toSeasonCode={season_code}"
        f"&sortDirection=ascending&statistic="
    )
    try:
        print(f"ğŸ” Fallback to HTML table: {web_url}")
        # Î”Î¹Î±Î²Î¬Î¶Î¿Ï…Î¼Îµ ÏŒÎ»Î¿Ï…Ï‚ Ï„Î¿Ï…Ï‚ Ï€Î¯Î½Î±ÎºÎµÏ‚Â· ÏƒÏ…Î½Î®Î¸Ï‰Ï‚ Î¿ 1Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Ï„Î± player stats
        tables = pd.read_html(web_url)  # Î±Ï€Î±Î¹Ï„ÎµÎ¯ lxml
        if not tables:
            print("âš ï¸ No tables found on expanded page")
            return pd.DataFrame()
        df = tables[0].copy()
        print(f"âœ… Scraped HTML table with shape: {df.shape}")

        # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÎµÏ†Î±Î»Î¯Î´Ï‰Î½ (Î±Ï†Î±Î¹ÏÎ¿ÏÎ¼Îµ ÎºÎµÎ½Î¬/Î¼Î·-Î±Î»Ï†Î±ÏÎ¹Î¸Î¼Î·Ï„Î¹ÎºÎ¬, Ï€.Ï‡. '3P%' â†’ '3P%')
        df.columns = [re.sub(r"\s+", " ", str(c)).strip() for c in df.columns]

        # Î£Ï…Ï‡Î½Î¬ Î· 1Î· ÏƒÏ„Î®Î»Î· ÎµÎ¯Î½Î±Î¹ index/# â€” Ï„Î·Î½ Ï€ÎµÏ„Î¬Î¼Îµ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
        if df.columns[0].lower() in {"#", "unnamed: 0"}:
            df = df.iloc[:, 1:]

        # ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® Ï€ÏÎ¿Ï†Î±Î½ÏÎ½ numeric (ÏŒ,Ï„Î¹ Î¼Î¿Î¹Î¬Î¶ÎµÎ¹ Î¼Îµ Ï€Î¿ÏƒÎ¿ÏƒÏ„ÏŒ/Î±ÏÎ¹Î¸Î¼ÏŒ)
        for col in df.columns:
            # Î ÏÎ¿ÏƒÏ€Î±Î¸Î¿ÏÎ¼Îµ Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ numeric ÏŒÏ€Î¿Ï… Î³Î¯Î½ÎµÏ„Î±Î¹, Ï‡Ï‰ÏÎ¯Ï‚ ÏƒÏ†Î¬Î»Î¼Î±
            df[col] = pd.to_numeric(df[col].astype(str).str.replace("%", "", regex=False)
                                    .str.replace(",", ".", regex=False), errors="ignore")

        return df
    except Exception as e:
        print(f"âŒ HTML scrape failed: {e}")
        # Î¤ÎµÎ»Î¹ÎºÏŒ fallback: ÎºÎµÎ½ÏŒ DF Î¼Îµ Î¼Î®Î½Ï…Î¼Î±
        return pd.DataFrame()




def write_outputs(df: pd.DataFrame, season: int, mode: str, out_dir: str):
    os.makedirs(out_dir, exist_ok=True)
    csv_path = os.path.join(out_dir, f"players_{season}_{mode}.csv")
    xlsx_path = os.path.join(out_dir, f"players_{season}_{mode}.xlsx")
    db_path = os.path.join(out_dir, "euroleague.db")

    # ÎšÎ±Î½Î¿Î½Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î²Î±ÏƒÎ¹ÎºÏÎ½ aliases ÏƒÏ„Î·Î»ÏÎ½ (Î±Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½)
    colmap = {
        "player_name": "Player",
        "team_name": "Team",
        "pts": "PTS",
        "reb": "REB",
        "ast": "AST",
        "stl": "STL",
        "blk": "BLK",
        "min": "MIN",
        "fg3m": "3PM",
        "fg3a": "3PA",
        "fg3pct": "3P%",
        "fg2m": "2PM",
        "fg2a": "2PA",
        "fg2pct": "2P%",
        "ftm": "FTM",
        "fta": "FTA",
        "ftpct": "FT%",
        "oreb": "OREB",
        "dreb": "DREB",
        "tov": "TOV",
        "pf": "PF",
        "gp": "GP",
        "gs": "GS",
    }
    for k, v in colmap.items():
        if k in df.columns and v not in df.columns:
            df[v] = df[k]

    df.to_csv(csv_path, index=False)
    try:
        df.to_excel(xlsx_path, index=False)
    except Exception:
        pass

    # SQLite
    import sqlite3
    con = sqlite3.connect(db_path)
    df.to_sql("player_stats", con, if_exists="replace", index=False)
    con.close()

    return csv_path, xlsx_path, db_path

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--seasons", nargs="+", type=int, help="Î .Ï‡. 2025 2024", required=False)
    parser.add_argument("--mode", type=str, default="perGame", choices=["perGame", "perMinute", "accumulated"])
    parser.add_argument("--competition", type=str, default="E", help="E=EuroLeague, U=EuroCup")
    parser.add_argument("--out", type=str, default="out", help="Î¦Î¬ÎºÎµÎ»Î¿Ï‚ ÎµÎ¾ÏŒÎ´Î¿Ï…")
    parser.add_argument("--force-raw", action="store_true", help="Î Î±ÏÎ¬ÎºÎ±Î¼ÏˆÎ· Î²Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ·Ï‚ ÎºÎ±Î¹ Ï‡ÏÎ®ÏƒÎ· raw HTTP")
    args = parser.parse_args()

    # Î¦ÏŒÏÏ„Ï‰ÏƒÎµ config Î±Î½ Î´ÎµÎ½ Î´Î¿Î¸Î¿ÏÎ½ seasons
    cfg_path = "config.json"
    if args.seasons is None and os.path.exists(cfg_path):
        with open(cfg_path, "r", encoding="utf-8") as f:
            cfg = json.load(f)
        seasons = cfg.get("seasons", [2025])
        mode = cfg.get("statistic_mode", args.mode)
        competition = cfg.get("competition_code", args.competition)
        out_dir = cfg.get("output_dir", args.out)
    else:
        seasons = args.seasons or [2025]
        mode = args.mode
        competition = args.competition
        out_dir = args.out

    used_raw = False
    for season in seasons:
        try:
            if args.force_raw:
                used_raw = True
                df = fetch_with_raw_requests(season, competition, mode)
            else:
                try:
                    df = fetch_with_package(season, competition, mode)
                except Exception:
                    used_raw = True
                    df = fetch_with_raw_requests(season, competition, mode)
        except Exception as e:
            print(f"[Î£Ï†Î¬Î»Î¼Î±] Season {season}: {e}", file=sys.stderr)
            continue

        # Advanced metrics enrichment
        try:
            df = add_advanced_metrics(df)
        except Exception as _e:
            print(f"[Î ÏÎ¿ÎµÎ¹Î´Î¿Ï€Î¿Î¯Î·ÏƒÎ·] Advanced metrics: {_e}")
        csv_path, xlsx_path, db_path = write_outputs(df, season, mode, out_dir)
        print(f"âœ” Season {season}:")
        print(f"  - CSV:  {csv_path}")
        print(f"  - XLSX: {xlsx_path}")
        print(f"  - DB:   {db_path}")
    if used_raw:
        print("\n(Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î®Î¸Î·ÎºÎµ fallback Î¼Îµ raw HTTP â€” Î±Î½ ÎºÎ¬Ï„Î¹ Î´ÎµÎ½ ÎºÎ±Ï„Î­Î²Î·ÎºÎµ, Î­Î»ÎµÎ³Î¾Îµ Ï„Î± endpoints/headers.)")

if __name__ == "__main__":
    main()
